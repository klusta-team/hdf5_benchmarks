{
 "metadata": {
  "name": "",
  "signature": "sha256:1d64c3a6a6d97ab45f14c0f7c1c287324b9d71aa1025fcddb4ac7db78a90434b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Bringing sparse arrays to HDF5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We currently store features and waveforms in huge dense arrays.\n",
      "\n",
      "* For waveforms, we store for each spike, the time course of the waveform on *all* channels. We end up with a `(Nspikes, Nsamples, Nchannels)` array.\n",
      "\n",
      "* For features, we store for each spike, the PCA components of each spike over *all* channels. We end up with a `(Nspikes, Nfeatures)` array."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With very large probes (>100 channels), it will be far more memory-efficient to store those arrays as **sparse** arrays instead of dense arrays. The reason is that each spike will only contain information on a small subset of channels (*unmasked* channels). This is a qualitative difference with small probes like tetrodes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The problem is that HDF5 does not support sparse arrays (to my knowledge). We need to implement such support ourselves. What we need is:\n",
      "\n",
      "* Only storing unmasked components. Masked components are set to 0. We could save the statistics of the noise (mean and variance) in a separate structure.\n",
      "* Fast row access. Each row corresponds to a spike, and we want to access to an arbitrary selection of spikes. We'll rarely want to store the whole array in memory.\n",
      "* We may also want to represent the sparse array in memory, so we'll also need in-memory data structure."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Numbers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are a few numbers to get an idea of the size of the data with very large probes. We choose high estimates because we'll use those numbers to determine the appropriate number of bytes for the data structures. **All estimates are given for the waveforms array**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "2**8, 2**16, 2**32"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "(256, 65536, 4294967296L)"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nchannels = 1e4  # number of channels\n",
      "nsamples = 100  # samples per waveform per channel\n",
      "nchannels_per_spike = 10  # average number of unmasked channels per spike\n",
      "duration = 1e4  # total duration of 1 experiment, in seconds (can contain \n",
      "                # multiple recordings, but all spikes are concatenated for spike sorting)\n",
      "nneurons = nchannels * 5  # let's assume 5 individual neurons per channel?\n",
      "average_rate = 1. # average firing rate of the neurons, in Hz\n",
      "nspikes = nneurons * average_rate * duration  # number of spikes\n",
      "nfeatures_per_channel = 3  # number of PCA features per channel\n",
      "print \"{0:d} millions of spikes\" .format(int(nspikes/1e6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "500 millions of spikes\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbytes_cols = 4  # max columns = nchannels_max = 4.3e9\n",
      "nbytes_data = 2  # int16 data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nvalues_unmasked = nspikes*nsamples*nchannels_per_spike\n",
      "print \"{0:d} billions of unmasked values\" .format(int(nvalues_unmasked/1e9))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "500 billions of unmasked values\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wave_shape = (nspikes, nsamples, nchannels)\n",
      "dense_size = np.prod(wave_shape) * nbytes_data\n",
      "print \"Dense size: {0:.1f} TB!\".format(dense_size/1024**4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dense size: 909.5 TB!\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Waveforms and features arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Waveforms are currently stored in a 3D array of size `(Nspikes, Nsamples, Nchannels)`. However, we may need to change this to `(Nspikes, Nchannels, Nsamples)`. The reason is that with the C order convention (default in NumPy and HDF5), we want contiguous unmasked data in the late dimensions. With the current layout, we'll waste a lot of space in sparse structures detailled below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we do this change, we can consider this 3D array as a 2D array of size `(Nspikes, Nchannels * Nsamples)` (\"free\" reshape with the same memory layout in C order). Unmasked data will be mostly contiguous on each row. **Hence, from now on, we'll only consider 2D arrays**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is only true if we make the following assumption:\n",
      "\n",
      "**(H_CC): channels are indexed in contiguous order**. In other words, channel indices are topologically sorted according to the geometrical layout of the probe (channel i is physically close to channel i+1)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This assumption will simplify the possible sparse structures."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sparse structures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are three propositions for sparse structures adapted to our cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These structures can be easily implemented in HDF5: [one just needs to store the different elements of the structure as regular contiguous arrays](http://stackoverflow.com/questions/11129429/storing-numpy-sparse-matrix-in-hdf5-pytables). The different structures differ in memory efficiency, and how well they are adapted to our data access patterns."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's precise our data access patterns:\n",
      "\n",
      "* **Pattern W** (waveforms): loop over a small number of rows arbitrarily spread in the array, and extract all unmasked values from those rows. \n",
      "* **Pattern F** (features): loop over a large number of rows regularly spread in the array, and extract all unmasked values from those rows. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For pattern W, we need those values for *display* only, and we'll eventually need a contiguous dense NumPy array in memory to display with OpenGL."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For pattern F, we need those values for both computations (sparse might be ok if SciPy knows how to perform matrix operations on them) and display (need for contiguous dense NumPy arrays)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need efficient out-of-memory read access (without loading the whole array in memory)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Proposition 1: Compressed Sparse Row matrix (CSR)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classic [sparse structure](http://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR_or_CRS.29). Three elements:\n",
      "\n",
      "* `data`: unmasked data in a contiguous 1D array\n",
      "* `indices`: the column of each unmasked value (same size as data)\n",
      "* `indptr`: for each row, the index of the first unmasked value on that row. The last element in this vector is the length of `data`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.sparse as sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = array([1,2,3,4,5,6])\n",
      "indices = array([0,2,2,0,1,2])\n",
      "indptr = array([0,2,3,6])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp.csr_matrix( (data,indices,indptr), shape=(3,3) ).todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "matrix([[1, 0, 2],\n",
        "        [0, 0, 3],\n",
        "        [4, 5, 6]])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Pros**\n",
      "\n",
      "* general structure, no assumption whatsoever\n",
      "* already [implemented in SciPy](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html#scipy.sparse.bsr_matrix)\n",
      "* efficient for pattern W"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Cons**\n",
      "\n",
      "* not very space-efficient\n",
      "* not very efficient for pattern F"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_size = nvalues_unmasked * nbytes_data\n",
      "indices_size = nvalues_unmasked * 4  # int32 to address any columns (max nchannels=4e9)\n",
      "indptr_size = nspikes * 8  # need int64 to address all unmasked values\n",
      "csr_size = data_size+indices_size+indptr_size\n",
      "print \"CSR size: {0:.1f} TB\".format(csr_size/1024**4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CSR size: 2.7 TB\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Proposition 2: dense array with shifted columns (DSC)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: this format is not standard as far as I know."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use standard dense contiguous arrays, but with a smaller number of columns. The idea is that every row contains a contiguous block of unmasked data from column $i$ to column $j$, with $j-i \\ll n_{cols}$. We choose a maximum value for the block size $j-i$, and we store every block there. There is some waste if the average block size is significantly smaller than the maximum block size. We also need to store $i$ and $j$ for each row."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_nchannels_per_spike = nchannels_per_spike*1.5  # average nchannels per spike + 50%\n",
      "data_size = nspikes * nsamples * max_nchannels_per_spike * nbytes_data\n",
      "indices_size = nspikes*2*4  # for each spike, 2 int32 column indices\n",
      "dsc_size = data_size + indices_size\n",
      "print \"DSC size: {0:.1f} TB\".format(dsc_size/1024**4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DSC size: 1.4 TB\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Pros**\n",
      "\n",
      "* more space-efficient than CSR\n",
      "* efficient for pattern W\n",
      "* efficient for pattern F (HDF5 hyperslab on contiguous array)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Cons**\n",
      "\n",
      "* need to limit the maximum number of columns per row\n",
      "* need **(H_CC)** (contiguous channel indexing)\n",
      "* need to change the waveform layout to have Nsamples as last dimension\n",
      "* out-of-memory computations with NumPy may be hard to implement?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Proposition 3: Compressed Sparse Row Block matrix (CSBR)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: this format is not standard as far as I know."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Like classic CSR, but we just store the first and last unmasked value per row, instead of storing the indices of *all* unmasked values per row."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_size = nspikes * nsamples * nchannels_per_spike * nbytes_data\n",
      "indices_size = nspikes*2*4  # for each spike, 2 int32 column indices\n",
      "csbr_size = data_size + indices_size\n",
      "print \"CSBR size: {0:.1f} TB\".format(csbr_size/1024**4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CSBR size: 0.9 TB\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Pros**\n",
      "\n",
      "* the most space-efficient\n",
      "* efficient for pattern W"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Cons**\n",
      "\n",
      "* not very efficient for pattern F\n",
      "* need **(H_CC)** (contiguous channel indexing)\n",
      "* need to change the waveform layout to have Nsamples as last dimension\n",
      "* not standard in SciPy: need to implement out-of-memory computations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Conclusions\n",
      "\n",
      "* We definitely need sparse HDF5 arrays in the relatively short term. Disk space is cheap, but not that cheap (in terms of money, physical space and transfer time).\n",
      "* Achieving memory and speed efficiency with sparse arrays in HDF5 is tricky.\n",
      "* We probably won't be able to use an existing implementation and we'll need to design and implement everything ourselves.\n",
      "* I have a slight preference for proposition 3.\n",
      "* The choice of the structure is likely to impact the way we implement many spike sorting steps (for example how we compute the similarity matrix, etc.).\n",
      "* We need to think thoroughly about those processing steps, particularly if we move to template-matching algorithms. How will we write and read data, for computations, display, etc.? For example, pattern F comes directly from the way the manual stage is done in the FeatureView in KlustaViewa.\n",
      "* Once everything is implemented, it will be hard to move to another format in the mid-term. Therefore, this format should scale to most datasets that will be available within the next ~5 years."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}